{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from train_lstm import perplexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc_train_input='../data/1.en'\n",
    "dec_train_input='../data/1.ru'\n",
    "num_buckets=1\n",
    "num_layers=3\n",
    "num_hidden=10\n",
    "batch_size=1\n",
    "iterations=1\n",
    "expt_name='simple'\n",
    "params_dir='../params'\n",
    "shuffle=False\n",
    "reverse=True\n",
    "top_words=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from text_io import filter_text, get_vocab, text_2_indices, get_unified_vocab, get_data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2idx, idx2word = get_unified_vocab(enc_train_input, dec_train_input, top_words)\n",
    "train_data_label = get_data_label(enc_train_input, dec_train_input, word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell(num_hidden, indata, mask, prev_state, param, seqidx, layeridx, dropout=0.):\n",
    "    \"\"\"LSTM Cell symbol\"\"\"\n",
    "    if dropout > 0.:\n",
    "        indata = mx.sym.Dropout(data=indata, p=dropout)\n",
    "    i2h = mx.sym.FullyConnected(\n",
    "        data=indata,\n",
    "        weight=param.i2h_weight,\n",
    "        bias=param.i2h_bias,\n",
    "        num_hidden=num_hidden * 4,\n",
    "        name=\"t%d_l%d_i2h\" % (seqidx, layeridx)\n",
    "    )\n",
    "\n",
    "    h2h = mx.sym.FullyConnected(\n",
    "        data=prev_state.h,\n",
    "        weight=param.h2h_weight,\n",
    "        bias=param.h2h_bias,\n",
    "        num_hidden=num_hidden * 4,\n",
    "        name=\"t%d_l%d_h2h\" % (seqidx, layeridx)\n",
    "    )\n",
    "\n",
    "    gates = i2h + h2h\n",
    "    slice_gates = mx.sym.SliceChannel(gates, num_outputs=4, name=\"t%d_l%d_slice\" % (seqidx, layeridx))\n",
    "\n",
    "    in_gate = mx.sym.Activation(slice_gates[0], act_type=\"sigmoid\")\n",
    "    in_transform = mx.sym.Activation(slice_gates[1], act_type=\"tanh\")\n",
    "    forget_gate = mx.sym.Activation(slice_gates[2], act_type=\"sigmoid\")\n",
    "    out_gate = mx.sym.Activation(slice_gates[3], act_type=\"sigmoid\")\n",
    "\n",
    "    next_c = (forget_gate * prev_state.c) + (in_gate * in_transform)\n",
    "    next_h = out_gate * mx.sym.Activation(next_c, act_type=\"tanh\")\n",
    "    \n",
    "    # mask out the output\n",
    "    next_c = mx.sym.element_mask(next_c, mask)\n",
    "    next_h = mx.sym.element_mask(next_h, mask)\n",
    "\n",
    "    return LSTMState(c=next_c, h=next_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import mxnet as mx\n",
    "# import numpy as np\n",
    "\n",
    "from lstm import LSTMState, LSTMParam, init_lstm\n",
    "\n",
    "def lstm_unroll(num_lstm_layer, enc_len, dec_len, num_hidden, num_labels, dropout=0.0):\n",
    "    cls_weight = mx.sym.Variable(\"cls_weight\")\n",
    "    cls_bias = mx.sym.Variable(\"cls_bias\")\n",
    "    embed_weight=mx.sym.Variable(\"embed_weight\")\n",
    "    \n",
    "    enc_param_cells, last_states = init_lstm(num_lstm_layer, prefix='enc')\n",
    "    dec_param_cells, _ = init_lstm(num_lstm_layer, prefix='dec')\n",
    "    \n",
    "    data  = mx.sym.Variable('data')\n",
    "    label = mx.sym.Variable('label')\n",
    "    mask  = mx.sym.Variable('mask')\n",
    "\n",
    "    # (batch, time, vec) so axis 1 is the time step\n",
    "    \n",
    "    embed = mx.sym.Embedding(\n",
    "        data=data, input_dim=num_labels,\n",
    "        weight=embed_weight, output_dim=num_hidden, name='embed'\n",
    "    )\n",
    "    \n",
    "    # num_hidden = 10\n",
    "    # data is a sequence of index (0,1,2,3)\n",
    "    # embedding -> 10 x 4 matrix...\n",
    "    # each column is the word embedding vector \n",
    "    \n",
    "    wordvec = mx.sym.SliceChannel(data=embed, num_outputs=enc_len + dec_len, squeeze_axis=1)\n",
    "    maskvec   = mx.sym.SliceChannel(data=mask,  num_outputs=enc_len + dec_len, squeeze_axis=1)\n",
    "    \n",
    "    # numpy array is (2,3) => (2,3)\n",
    "    # numpy array is (1,3) => (3,)\n",
    "    \n",
    "    hidden_all = []\n",
    "    for seqidx in range(enc_len + dec_len):\n",
    "        hidden = wordvec[seqidx]\n",
    "        mask_in = maskvec[seqidx]\n",
    "        \n",
    "        # stack LSTM\n",
    "        for i in range(num_lstm_layer):\n",
    "            dp = 0.0 if i == 0 else dropout\n",
    "            \n",
    "            # encoder RNN\n",
    "            next_state = lstm_cell(\n",
    "                num_hidden,\n",
    "                indata     = hidden,\n",
    "                mask       = mask_in,\n",
    "                prev_state = last_states[i],\n",
    "                param      = enc_param_cells[i] if seqidx < enc_len else dec_param_cells[i],\n",
    "                seqidx     = seqidx,\n",
    "                layeridx   = i,\n",
    "                dropout    = dp\n",
    "            )\n",
    "\n",
    "            hidden = next_state.h\n",
    "            last_states[i] = next_state\n",
    "            \n",
    "        if dropout > 0.0:\n",
    "            hidden = mx.sym.Dropout(data=hidden, p=dropout)\n",
    "        \n",
    "        if(seqidx >= enc_len):\n",
    "            hidden_all.append(hidden)\n",
    "        \n",
    "    hidden_concat = mx.sym.Concat(*hidden_all, dim=0)\n",
    "    pred = mx.sym.FullyConnected(\n",
    "        data=hidden_concat,\n",
    "        num_hidden=num_labels, # num_labels is the index of <PAD> that means this layer will predict 0, 1, ..., num_labels-1\n",
    "        weight=cls_weight,\n",
    "        bias=cls_bias,\n",
    "        name='pred'\n",
    "    )\n",
    "    \n",
    "    # hidden comes from lstm... output of 1 lstm is a vector...\n",
    "    # hidden_concat -> every column is the vector of each lstm at each time step\n",
    "    \n",
    "    # softmax = e^(- w' * x) / \\sum e^(- w' * x) <-- richard thinks this is softmax\n",
    "    # softmax = e^(-x) / \\sum_i e^(-x_i)\n",
    "    \n",
    "    # output of 1 lstm (top) is a vector of H dimensions...\n",
    "    # SoftmaxOutput => e^(x) / (1+e^(x)), x is a scalar\n",
    "    # output of lstm is a vector\n",
    "\n",
    "    label = mx.sym.transpose(data=label) # e.g. if shape is (1,M) it becomes (M,1)\n",
    "    label = mx.sym.Reshape(data=label, shape=(-1,)) # if shape is (M,1) it becomes (M,)\n",
    "    output = mx.sym.SoftmaxOutput(\n",
    "        data=pred,\n",
    "        label=label,\n",
    "        name='t%d_softmax' % seqidx,\n",
    "        use_ignore=True,\n",
    "        ignore_label=num_labels # ignore the index of <PAD>\n",
    "    ) # output becomes (num_labels, M)\n",
    "    return output\n",
    "\n",
    "def get_lstm_sym_generator(num_layers, num_hidden, num_labels, dropout=0.0):\n",
    "    def generate_lstm_sym(bucketkey):\n",
    "        return lstm_unroll(num_layers, bucketkey.enc_len, bucketkey.dec_len, num_hidden, num_labels, dropout)\n",
    "    return generate_lstm_sym\n",
    "\n",
    "def get_lstm_init_states(num_layers, num_dim, batch_size=1):\n",
    "    init_h = [('l%d_init_h' % i, (batch_size, num_dim)) for i in range(num_layers)]\n",
    "    init_c = [('l%d_init_c' % i, (batch_size, num_dim)) for i in range(num_layers)]\n",
    "    init_states = init_h + init_c\n",
    "    return init_states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from collections import namedtuple\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "EncDecBucketKey = namedtuple('EncDecBucketKey', ['enc_len', 'dec_len'])\n",
    "\n",
    "class EncoderDecoderBatch(object):\n",
    "    def __init__(self, all_data, all_mask, all_label, init_states, bucket_key):\n",
    "        # provide data, essential assignment\n",
    "        # need to optimize this list creation!!!\n",
    "        self.data = [ mx.nd.array(all_data), mx.nd.array(all_mask) ] + [ mx.nd.zeros(x[1]) for x in init_states ]\n",
    "\n",
    "        # provide label, essential assignment\n",
    "        self.label = [ mx.nd.array(all_label) ]\n",
    "\n",
    "        self.init_states = init_states\n",
    "\n",
    "        # bucket_key is essential for this databatch\n",
    "        self.bucket_key = bucket_key\n",
    "\n",
    "        #all_data.shape is (x,y,z)\n",
    "        self.batch_size = all_data.shape[0]\n",
    "\n",
    "    # this two properties are essential too!\n",
    "    @property\n",
    "    def provide_data(self):\n",
    "        return [\n",
    "            ('data', (self.batch_size, self.bucket_key.enc_len + self.bucket_key.dec_len)),\n",
    "            ('mask', (self.batch_size, self.bucket_key.enc_len + self.bucket_key.dec_len))\n",
    "        ] + self.init_states\n",
    "\n",
    "    @property\n",
    "    def provide_label(self):\n",
    "        return [('label', (self.batch_size, self.bucket_key.dec_len))]\n",
    "\n",
    "\n",
    "def synchronize_batch_size(train_iter, test_iter):\n",
    "    batch_size = min(train_iter.batch_size, test_iter.batch_size)\n",
    "    train_iter.batch_size = batch_size\n",
    "    test_iter.batch_size = batch_size\n",
    "    train_iter.generate_init_states()\n",
    "    test_iter.generate_init_states()\n",
    "\n",
    "\n",
    "# now define the bucketing, padding and batching SequenceIterator...\n",
    "class EncoderDecoderIter(mx.io.DataIter):\n",
    "    def __init__(self, data_label, word2idx, idx2word, num_hidden, num_layers, \n",
    "                 init_states_function, batch_size=1, num_buckets=10, shuffle=False, rev=False):\n",
    "\n",
    "        super(EncoderDecoderIter, self).__init__() # calling DataIter.__init__()\n",
    "\n",
    "        # data is a numpy array of 3 dimensions, (#, timesteps, vector_dim)\n",
    "        # let's say you have 2 sequences, #1 has len 5, dimension 10\n",
    "        self.data_label = data_label #numpy multi-dimensional array\n",
    "        \n",
    "        # data_label[i] is the ith sequence\n",
    "        \n",
    "        \n",
    "        self.word2idx = word2idx\n",
    "        self.idx2word = idx2word\n",
    "\n",
    "        self.num_hidden = num_hidden\n",
    "        self.num_layers = num_layers\n",
    "        self.num_buckets = num_buckets\n",
    "\n",
    "        # arrange the data so that\n",
    "\n",
    "        # now we need to find the buckets based on the input data...\n",
    "        self.buckets, self.buckets_count, self.assignments = self.generate_buckets()\n",
    "        # buckets are a tuple of the encoder/decoder length\n",
    "\n",
    "        self.batch_size = min(np.min(self.buckets_count), batch_size)\n",
    "        self.init_states_function = init_states_function\n",
    "        self.pad_label = word2idx['<PAD>']\n",
    "        self.shuffle = shuffle\n",
    "        self.rev = rev # reverse the encoder input\n",
    "        self.reset()\n",
    "        self.generate_init_states()\n",
    "\n",
    "    def generate_init_states(self):\n",
    "        self.init_states = self.init_states_function(self.num_layers, self.num_hidden, self.batch_size)\n",
    "\n",
    "    def generate_buckets(self):\n",
    "        enc_dec_data = []\n",
    "        for data, label in self.data_label:\n",
    "            enc_len = len(data) - 1 # minue one because of the <EOS>\n",
    "            dec_len = len(label)\n",
    "            enc_dec_data.append((enc_len, dec_len))\n",
    "\n",
    "        enc_dec_data = np.array(enc_dec_data)\n",
    "\n",
    "        kmeans = KMeans(n_clusters = self.num_buckets, random_state = 1) # use clustering to decide the buckets\n",
    "        assignments = kmeans.fit_predict(enc_dec_data) # get the assignments\n",
    "\n",
    "        # get the max of every cluster\n",
    "        buckets = np.array([np.max( enc_dec_data[assignments==i], axis=0 ) for i in range(self.num_buckets)])\n",
    "\n",
    "        # get # of sequences in each bucket... then assign the batch size as the minimum(minimum(bucketsize), batchsize)\n",
    "        buckets_count = np.array( [ enc_dec_data[assignments==i].shape[0] for i in range(self.num_buckets) ] )\n",
    "\n",
    "        return buckets, buckets_count, assignments\n",
    "\n",
    "    @property\n",
    "    def default_bucket_key(self):\n",
    "        enc_len, dec_len = np.max(self.buckets, axis=0)\n",
    "        return EncDecBucketKey(enc_len = enc_len, dec_len = dec_len)\n",
    "\n",
    "    @property\n",
    "    def provide_data(self): # this is necessary when specifying custom DataIter\n",
    "        # length of data variable is length of encoder + length of decoder\n",
    "        enc_dec_bucket_key = self.default_bucket_key\n",
    "\n",
    "        return [\n",
    "            ('data', (self.batch_size, enc_dec_bucket_key.enc_len + enc_dec_bucket_key.dec_len)),\n",
    "            ('mask', (self.batch_size, enc_dec_bucket_key.enc_len + enc_dec_bucket_key.dec_len))\n",
    "        ] + self.init_states\n",
    "    #\n",
    "    @property\n",
    "    def provide_label(self): # this is necessary when specifying custom DataIter\n",
    "        # length of label variable is only the length of decoder\n",
    "        enc_dec_bucket_key = self.default_bucket_key\n",
    "        return [('label', (self.batch_size, enc_dec_bucket_key.dec_len))]\n",
    "    \n",
    "    # for custom DataIter, we must implement this class as an iterable and return a DataBatch\n",
    "    def __iter__(self): # this is necessary to convert this class into an iterable\n",
    "        return self\n",
    "    \n",
    "    def __next__(self):\n",
    "        if self.iter_next():\n",
    "            # suppose to get self.cursor:self.cursor + self.batch_size\n",
    "            batch = self.data_label[self.assignments == self.cur_permute_bucket]\\\n",
    "                [ self.in_bucket_permutation[self.cursor:self.cursor+self.batch_size] ]\n",
    "\n",
    "            # get size of this bucket\n",
    "            enc_len, dec_len = self.buckets[self.cur_permute_bucket] # this enc_len already deducted the <EOS>\n",
    "            # total length of rnn sequence is enc_len+dec_len\n",
    "\n",
    "            all_data  = np.full((self.batch_size, enc_len+dec_len), self.pad_label, dtype=float)\n",
    "            all_label = np.full((self.batch_size, dec_len), self.pad_label, dtype=float)\n",
    "            all_mask = np.zeros((self.batch_size, enc_len+dec_len), dtype=float)\n",
    "\n",
    "            for i, (data, label) in enumerate(batch):\n",
    "                if self.rev:\n",
    "                    # reverse the input except for the <EOS> at end of input\n",
    "                    # according to Ilya Sutskever et al. Sequence to Sequence Learning with Neural Networks\n",
    "                    data[:-1] = np.flipud(data[:-1])\n",
    "                \n",
    "                enc_input = np.concatenate((data, label[:-1])) # data <EOS> label\n",
    "                z = enc_len - data.shape[0] + 1\n",
    "                all_data[i, z:enc_len + label.shape[0]] = enc_input\n",
    "                all_mask[i, z:enc_len + label.shape[0]] = 1.0\n",
    "                all_label[i, :label.shape[0]] = label\n",
    "\n",
    "            return EncoderDecoderBatch(all_data, all_mask, all_label, self.init_states, EncDecBucketKey(enc_len=enc_len, dec_len=dec_len))\n",
    "        else:\n",
    "            raise StopIteration\n",
    "    \n",
    "    def iter_next(self):\n",
    "        self.cursor += self.batch_size\n",
    "        if self.cursor < self.buckets_count[self.cur_permute_bucket]:\n",
    "            if self.cursor + self.batch_size > self.buckets_count[self.cur_permute_bucket]:\n",
    "                # it is going to overflow the bucket\n",
    "                self.cursor -= self.cursor + self.batch_size - self.buckets_count[self.cur_permute_bucket]\n",
    "            return True\n",
    "        else:\n",
    "            self.cur_bucket += 1\n",
    "            if self.cur_bucket < self.num_buckets:\n",
    "                self.cursor = 0\n",
    "                self.cur_permute_bucket = self.bucket_permutation[self.cur_bucket]\n",
    "                if self.shuffle:\n",
    "                    self.in_bucket_permutation = np.random.permutation(self.buckets_count[self.cur_permute_bucket])\n",
    "                else:\n",
    "                    self.in_bucket_permutation = np.array(range(self.buckets_count[self.cur_permute_bucket]))\n",
    "                return True\n",
    "            else:\n",
    "                return False\n",
    "\n",
    "    def reset(self): # for iterable\n",
    "        self.cursor = -self.batch_size\n",
    "        self.cur_bucket = 0\n",
    "\n",
    "        if self.shuffle:\n",
    "            self.bucket_permutation = np.random.permutation(self.num_buckets)\n",
    "        else:\n",
    "            self.bucket_permutation = np.array(range(self.num_buckets))\n",
    "\n",
    "        self.cur_permute_bucket = self.bucket_permutation[self.cur_bucket]\n",
    "        if self.shuffle:\n",
    "            self.in_bucket_permutation = np.random.permutation(self.buckets_count[self.cur_permute_bucket])\n",
    "        else:\n",
    "            self.in_bucket_permutation = np.array(range(self.buckets_count[self.cur_permute_bucket]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_iter = EncoderDecoderIter(train_data_label, word2idx, idx2word,\n",
    "            num_hidden, num_layers, get_lstm_init_states, batch_size=batch_size,\n",
    "            num_buckets=num_buckets, shuffle=shuffle, rev=reverse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def print_iter(iter):\n",
    "    iter.reset()\n",
    "    print('provide_data: ', iter.provide_data)\n",
    "    print('provide_label: ', iter.provide_label)\n",
    "    print('buckets: ', iter.buckets)\n",
    "    print('buckets count: ', iter.buckets_count)\n",
    "    print('assignments: ', iter.assignments)\n",
    "    print('batch_size: ', iter.batch_size)\n",
    "    for i, data_batch in enumerate(iter):\n",
    "        print(i, data_batch.provide_data)\n",
    "        print(i, data_batch.provide_label)\n",
    "        print(i, data_batch.bucket_key)\n",
    "#         print(i, data_batch.data)\n",
    "        for j, d in enumerate(data_batch.data):\n",
    "#             print(i, j, data_batch.data[j].shape)\n",
    "            if j==0:\n",
    "                print(i, 'data:', data_batch.data[j].asnumpy())\n",
    "            elif j==1:\n",
    "                print(i, 'mask:', data_batch.data[j].asnumpy())\n",
    "#         print(i, data_batch.label)\n",
    "#         print(i, data_batch.label[0].shape)\n",
    "        print(i, 'label:', data_batch.label[0].asnumpy())\n",
    "        print('\\n')\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx2word[42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "enc enc enc <eos> dec dec dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print_iter(train_iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data_label[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "word2idx['<EOS>']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os, re\n",
    "\n",
    "context = mx.cpu()\n",
    "\n",
    "model_args = {}\n",
    "if os.path.isfile('%s/%s-symbol.json' % (params_dir, expt_name)):\n",
    "    filelist = os.listdir(params_dir) # get list of params file\n",
    "    paramfilelist = []\n",
    "    for f in filelist:\n",
    "        if f.startswith('%s-' % expt_name) and f.endswith('.params'):\n",
    "            paramfilelist.append( int(re.split(r'[-.]', f)[1]) )\n",
    "    last_iteration = max(paramfilelist)\n",
    "    print('loading pretrained model %s/%s at epoch %d' % (params_dir, expt_name, last_iteration))\n",
    "    tmp = mx.model.FeedForward.load('%s/%s' % (params_dir, expt_name), last_iteration)\n",
    "    model_args.update({\n",
    "        'arg_params' : tmp.arg_params,\n",
    "        'aux_params' : tmp.aux_params,\n",
    "        'begin_epoch' : tmp.begin_epoch\n",
    "    })\n",
    "\n",
    "num_labels = len(word2idx)\n",
    "iterations = 600\n",
    "model = mx.model.FeedForward(\n",
    "    ctx           = context, # uses all the available CPU in the machine\n",
    "    symbol        = get_lstm_sym_generator(num_layers, num_hidden, num_labels),\n",
    "    num_epoch     = iterations,\n",
    "    learning_rate = 0.1,\n",
    "    momentum      = 0.0,\n",
    "    wd            = 0.00001,\n",
    "    initializer   = mx.init.Xavier(factor_type=\"in\", magnitude=2.34),\n",
    "    **model_args\n",
    ")\n",
    "\n",
    "if not os.path.exists(params_dir):\n",
    "    os.makedirs(params_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.fit(\n",
    "    X = train_iter,\n",
    "    eval_metric = mx.metric.np(perplexity, use_ignore=True, ignore_label=num_labels),\n",
    "    batch_end_callback = [ mx.callback.Speedometer(batch_size, frequent=10) ],\n",
    "    epoch_end_callback = [ mx.callback.do_checkpoint( '%s/%s' % (params_dir, expt_name) ) ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "params_dir = '../params'\n",
    "expt_name  = 'simple'\n",
    "num_labels = len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "last_iteration = 500\n",
    "print('loading pretrained model %s/%s at epoch %d' % (params_dir, expt_name, last_iteration))\n",
    "_, arg_params, __ = mx.model.load_checkpoint('%s/%s' % (params_dir, expt_name), last_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "arg_params['enc_l0_i2h_weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "idx2word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_cell_no_mask(num_hidden, indata, prev_state, param, seqidx, layeridx, dropout=0.):\n",
    "    \"\"\"LSTM Cell symbol\"\"\"\n",
    "    if dropout > 0.:\n",
    "        indata = mx.sym.Dropout(data=indata, p=dropout)\n",
    "    i2h = mx.sym.FullyConnected(\n",
    "        data=indata,\n",
    "        weight=param.i2h_weight,\n",
    "        bias=param.i2h_bias,\n",
    "        num_hidden=num_hidden * 4,\n",
    "        name=\"t%d_l%d_i2h\" % (seqidx, layeridx)\n",
    "    )\n",
    "\n",
    "    h2h = mx.sym.FullyConnected(\n",
    "        data=prev_state.h,\n",
    "        weight=param.h2h_weight,\n",
    "        bias=param.h2h_bias,\n",
    "        num_hidden=num_hidden * 4,\n",
    "        name=\"t%d_l%d_h2h\" % (seqidx, layeridx)\n",
    "    )\n",
    "\n",
    "    gates = i2h + h2h\n",
    "    slice_gates = mx.sym.SliceChannel(gates, num_outputs=4, name=\"t%d_l%d_slice\" % (seqidx, layeridx))\n",
    "\n",
    "    in_gate = mx.sym.Activation(slice_gates[0], act_type=\"sigmoid\")\n",
    "    in_transform = mx.sym.Activation(slice_gates[1], act_type=\"tanh\")\n",
    "    forget_gate = mx.sym.Activation(slice_gates[2], act_type=\"sigmoid\")\n",
    "    out_gate = mx.sym.Activation(slice_gates[3], act_type=\"sigmoid\")\n",
    "\n",
    "    next_c = (forget_gate * prev_state.c) + (in_gate * in_transform)\n",
    "    next_h = out_gate * mx.sym.Activation(next_c, act_type=\"tanh\")\n",
    "\n",
    "    return LSTMState(c=next_c, h=next_h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_inference_symbol(num_layer, num_hidden, num_labels, prefix, dropout=0.0):\n",
    "    param_cells, last_states = init_lstm(num_layer, prefix)\n",
    "    \n",
    "    data = mx.sym.Variable('data')\n",
    "    embed_weight=mx.sym.Variable(\"embed_weight\")\n",
    "    \n",
    "    hidden = mx.sym.Embedding(data=data, input_dim=num_labels, weight=embed_weight, output_dim=num_hidden, name='embed')\n",
    "    \n",
    "    # stack layers of LSTM for 1 sequence\n",
    "    for i in range(num_layer):\n",
    "        dp = 0.0 if i == 0 else dropout\n",
    "        next_state = lstm_cell_no_mask(\n",
    "            num_hidden,\n",
    "            indata=hidden,\n",
    "            prev_state=last_states[i],\n",
    "            param=param_cells[i],\n",
    "            seqidx=0,\n",
    "            layeridx=i,\n",
    "            dropout=dp\n",
    "        )\n",
    "        hidden = next_state.h\n",
    "        last_states[i] = next_state\n",
    "    \n",
    "    if dropout > 0.0:\n",
    "        hidden = mx.sym.Dropout(data=hidden, p=dropout)\n",
    "    \n",
    "    output = []\n",
    "    for state in last_states:\n",
    "        # very important to be in this order!!!\n",
    "        output.append(state.h)\n",
    "        output.append(state.c)\n",
    "    \n",
    "    return mx.sym.Group(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LSTMInferenceModel(object):\n",
    "    def __init__(self, num_layer, num_hidden, num_labels, arg_params, ctx=mx.cpu(), dropout=0.0):\n",
    "        \n",
    "        self.enc_sym = lstm_inference_symbol(num_layer, num_hidden, num_labels, 'enc', dropout)\n",
    "        self.dec_sym = lstm_inference_symbol(num_layer, num_hidden, num_labels, 'dec', dropout)\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        batch_size = 1\n",
    "        init_states = get_lstm_init_states(num_layer, num_hidden, batch_size)\n",
    "        data_shape = [(\"data\", (batch_size, ))]\n",
    "\n",
    "        input_shapes = dict(init_states + data_shape)\n",
    "        self.enc_executor = self.enc_sym.simple_bind(ctx=ctx, **input_shapes)\n",
    "        self.dec_executor = self.dec_sym.simple_bind(ctx=ctx, **input_shapes)\n",
    "\n",
    "        # copy the transition parameters over to executor\n",
    "        for key in self.enc_executor.arg_dict.keys():\n",
    "            if key in arg_params:\n",
    "                arg_params[key].copyto(self.enc_executor.arg_dict[key])\n",
    "        \n",
    "        for key in self.dec_executor.arg_dict.keys():\n",
    "            if key in arg_params:\n",
    "                arg_params[key].copyto(self.dec_executor.arg_dict[key])\n",
    "\n",
    "        state_name = []\n",
    "        for i in range(num_layer):\n",
    "            # very important to be in this order!!!\n",
    "            state_name.append(\"l%d_init_h\" % i)\n",
    "            state_name.append(\"l%d_init_c\" % i)\n",
    "\n",
    "        # this transfer the output of previous state to current\n",
    "        self.enc_states_dict = dict(zip(state_name, self.enc_executor.outputs)) \n",
    "        self.dec_states_dict = dict(zip(state_name, self.dec_executor.outputs)) \n",
    "\n",
    "        self.cls_weight = arg_params['cls_weight']\n",
    "        self.cls_bias   = arg_params['cls_bias']\n",
    "        self.ctx = ctx\n",
    "\n",
    "    def predict(self, x):\n",
    "        # another symbolic graph here... \n",
    "        data       = mx.sym.Variable('data')\n",
    "        cls_weight = mx.sym.Variable(\"cls_weight\")\n",
    "        cls_bias   = mx.sym.Variable(\"cls_bias\")\n",
    "    \n",
    "        pred = mx.sym.FullyConnected(\n",
    "            data       = data,\n",
    "            num_hidden = self.num_labels,\n",
    "            weight     = cls_weight,\n",
    "            bias       = cls_bias,\n",
    "            name       = 'pred'\n",
    "        )\n",
    "        \n",
    "        output = mx.sym.SoftmaxOutput(\n",
    "            data = pred,\n",
    "            name = 'softmax'\n",
    "        )\n",
    "        \n",
    "        executor = output.bind(ctx=self.ctx, args={\n",
    "            'data': x,\n",
    "            'cls_weight': self.cls_weight,\n",
    "            'cls_bias'  : self.cls_bias,\n",
    "            'softmax_label': mx.nd.array([0]) # this is a dummy label, just meant to fulfill the requirements...\n",
    "        })\n",
    "        \n",
    "        executor.forward()\n",
    "        prob = np.squeeze(executor.outputs[0].asnumpy())\n",
    "        return prob\n",
    "        \n",
    "    def forward(self, input_data, rnn_type, eos_idx, new_seq=False):\n",
    "        # input data is of shape (seqlen, dim)\n",
    "        # input data has to be of type numpy.array\n",
    "        \n",
    "        if rnn_type==0:\n",
    "            states_dict = self.enc_states_dict\n",
    "            executor = self.enc_executor\n",
    "        else:\n",
    "            states_dict = self.dec_states_dict\n",
    "            executor = self.dec_executor\n",
    "        \n",
    "        if new_seq == True:\n",
    "            # this is meant to reset the initial states to 0.0\n",
    "            for key in states_dict.keys():\n",
    "                executor.arg_dict[key][:] = 0.0\n",
    "        \n",
    "        for i, x in enumerate(input_data):\n",
    "            y = mx.nd.array([x]) # put it in a [] so that the shape becomes (1, xxx)\n",
    "            y.copyto(executor.arg_dict[\"data\"])\n",
    "            \n",
    "            if x==eos_idx:\n",
    "                # start to use decoder parameters...\n",
    "                states_dict = self.dec_states_dict\n",
    "                executor = self.dec_executor\n",
    "                for key in self.enc_states_dict.keys():\n",
    "                    self.enc_states_dict[key].copyto(executor.arg_dict[key])\n",
    "            \n",
    "            executor.forward() # move forward one step...\n",
    "            for key in states_dict.keys():\n",
    "                # copy the hidden and c to the init_states for the next sequence\n",
    "                states_dict[key].copyto(executor.arg_dict[key])\n",
    "        \n",
    "        return self.predict(states_dict['l2_init_h']) # change this to use last layer next time...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 = LSTMInferenceModel(num_layers, num_hidden, num_labels, arg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the word...\n",
    "def get_word(prob, idx2word, sample=True):\n",
    "    if sample:\n",
    "        cdf = np.cumsum(prob) / np.sum(prob)\n",
    "        idx = np.argmax(np.random.rand(1) < cdf)\n",
    "    else:\n",
    "        idx = np.argmax(prob)\n",
    "    return idx, idx2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def translate(text, model2, idx2word, reverse=True):\n",
    "    data = text_2_indices(word2idx, text)\n",
    "    if reverse:\n",
    "        data[:-1] = np.flipud(data[:-1])\n",
    "    eos_idx = word2idx['<EOS>']\n",
    "    \n",
    "    words = ''\n",
    "    prob = model2.forward(data, 0, word2idx['<EOS>'], new_seq=True)\n",
    "    idx, word = get_word(prob, idx2word, sample=False)\n",
    "    while idx != eos_idx:\n",
    "        words += word + ' '\n",
    "        prob = model2.forward(np.array([idx]), 1, word2idx['<EOS>'])\n",
    "        idx, word = get_word(prob, idx2word, sample=True)\n",
    "    \n",
    "    return words.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translate('i just ate my dinner', model2, idx2word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "я только что съел мой ужин"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "translate('good morning', model2, idx2word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
