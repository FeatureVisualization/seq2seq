{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "# for printing out the training information to console\n",
    "import logging\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.DEBUG)\n",
    "\n",
    "from lstm import init_lstm, lstm_cell, get_lstm_init_states\n",
    "from text_io import get_unified_vocab, text_2_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading pretrained model ../params/july28 at epoch 97\n"
     ]
    }
   ],
   "source": [
    "params_dir = '../params'\n",
    "expt_name  = 'july28'\n",
    "last_iteration = 97\n",
    "print('loading pretrained model %s/%s at epoch %d' % (params_dir, expt_name, last_iteration))\n",
    "_, arg_params, __ = mx.model.load_checkpoint('%s/%s' % (params_dir, expt_name), last_iteration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lstm_inference_symbol(num_layer, num_hidden, num_labels, dropout=0.0):\n",
    "    param_cells, last_states = init_lstm(num_layer)\n",
    "    \n",
    "    data = mx.sym.Variable('data')\n",
    "    embed_weight=mx.sym.Variable(\"embed_weight\")\n",
    "    \n",
    "    hidden = mx.sym.Embedding(data=data, input_dim=num_labels, weight=embed_weight, output_dim=num_hidden, name='embed')\n",
    "    \n",
    "    # stack layers of LSTM for 1 sequence\n",
    "    for i in range(num_layer):\n",
    "        dp = 0.0 if i == 0 else dropout\n",
    "        next_state = lstm_cell(\n",
    "            num_hidden,\n",
    "            indata=hidden,\n",
    "            prev_state=last_states[i],\n",
    "            param=param_cells[i],\n",
    "            seqidx=0,\n",
    "            layeridx=i,\n",
    "            dropout=dp\n",
    "        )\n",
    "        hidden = next_state.h\n",
    "        last_states[i] = next_state\n",
    "    \n",
    "    if dropout > 0.0:\n",
    "        hidden = mx.sym.Dropout(data=hidden, p=dropout)\n",
    "    \n",
    "    output = []\n",
    "    for state in last_states:\n",
    "        # very important to be in this order!!!\n",
    "        output.append(state.h)\n",
    "        output.append(state.c)\n",
    "    \n",
    "    return mx.sym.Group(output)\n",
    "\n",
    "class LSTMInferenceModel(object):\n",
    "    def __init__(self, num_layer, num_hidden, num_labels, arg_params, ctx=mx.cpu(), dropout=0.0):\n",
    "        \n",
    "        self.sym = lstm_inference_symbol(num_layer, num_hidden, num_labels, dropout)\n",
    "        self.num_labels = num_labels\n",
    "        \n",
    "        batch_size = 1\n",
    "        init_states = get_lstm_init_states(num_layer, num_hidden, batch_size)\n",
    "        data_shape = [(\"data\", (batch_size, ))]\n",
    "\n",
    "        input_shapes = dict(init_states + data_shape)\n",
    "        self.executor = self.sym.simple_bind(ctx=ctx, **input_shapes)\n",
    "\n",
    "        # copy the transition parameters over to executor\n",
    "        for key in self.executor.arg_dict.keys():\n",
    "            if key in arg_params:\n",
    "                arg_params[key].copyto(self.executor.arg_dict[key])\n",
    "\n",
    "        state_name = []\n",
    "        for i in range(num_layer):\n",
    "            # very important to be in this order!!!\n",
    "            state_name.append(\"l%d_init_h\" % i)\n",
    "            state_name.append(\"l%d_init_c\" % i)\n",
    "\n",
    "        self.states_dict = dict(zip(state_name, self.executor.outputs)) # this transfer the output of previous state to current\n",
    "\n",
    "        self.cls_weight = arg_params['cls_weight']\n",
    "        self.cls_bias   = arg_params['cls_bias']\n",
    "        self.ctx = ctx\n",
    "\n",
    "    def predict(self, x):\n",
    "        # another symbolic graph here... \n",
    "        data       = mx.sym.Variable('data')\n",
    "        cls_weight = mx.sym.Variable(\"cls_weight\")\n",
    "        cls_bias   = mx.sym.Variable(\"cls_bias\")\n",
    "    \n",
    "        pred = mx.sym.FullyConnected(\n",
    "            data       = data,\n",
    "            num_hidden = self.num_labels,\n",
    "            weight     = cls_weight,\n",
    "            bias       = cls_bias,\n",
    "            name       = 'pred'\n",
    "        )\n",
    "        \n",
    "        output = mx.sym.SoftmaxOutput(\n",
    "            data = pred,\n",
    "            name = 'softmax'\n",
    "        )\n",
    "        \n",
    "        executor = output.bind(ctx=self.ctx, args={\n",
    "            'data': x,\n",
    "            'cls_weight': self.cls_weight,\n",
    "            'cls_bias'  : self.cls_bias,\n",
    "            'softmax_label': mx.nd.array([0]) # this is a dummy label, just meant to fulfill the requirements...\n",
    "        })\n",
    "        \n",
    "        executor.forward()\n",
    "        prob = np.squeeze(executor.outputs[0].asnumpy())\n",
    "        return prob\n",
    "        \n",
    "    def forward(self, input_data, new_seq=False):\n",
    "        # input data is of shape (seqlen, dim)\n",
    "        # input data has to be of type numpy.array\n",
    "        if new_seq == True:\n",
    "            # this is meant to reset the initial states to 0.0\n",
    "            for key in self.states_dict.keys():\n",
    "                self.executor.arg_dict[key][:] = 0.0\n",
    "        \n",
    "        for x in input_data:\n",
    "            y = mx.nd.array([x]) # put it in a [] so that the shape becomes (1, xxx)\n",
    "            y.copyto(self.executor.arg_dict[\"data\"])\n",
    "            self.executor.forward() # move forward one step...\n",
    "            for key in self.states_dict.keys():\n",
    "                # copy the hidden and c to the init_states for the next sequence\n",
    "                self.states_dict[key].copyto(self.executor.arg_dict[key])\n",
    "        \n",
    "        return self.predict(self.states_dict['l2_init_h']) # change this to use last layer next time...    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42569, 200)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arg_params['embed_weight'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_en_file = '../data/train.en'\n",
    "train_ru_file = '../data/train.ru'\n",
    "word2idx, idx2word = get_unified_vocab(train_en_file, train_ru_file, 80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42569\n"
     ]
    }
   ],
   "source": [
    "num_labels = len(idx2word)\n",
    "print(num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "num_layers = 3\n",
    "num_hidden = arg_params['embed_weight'].shape[1]\n",
    "model = LSTMInferenceModel(num_layers, num_hidden, num_labels, arg_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the word...\n",
    "def get_word(prob, idx2word, sample=True):\n",
    "    if sample:\n",
    "        cdf = np.cumsum(prob) / np.sum(prob)\n",
    "        idx = np.argmax(np.random.rand(1) < cdf)\n",
    "    else:\n",
    "        idx = np.argmax(prob)\n",
    "    return idx, idx2word[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def translate(text, model2, idx2word, reverse=True, sample=True):\n",
    "    data = text_2_indices(word2idx, text)\n",
    "    if reverse:\n",
    "        data[:-1] = np.flipud(data[:-1])\n",
    "    eos_idx = word2idx['<EOS>']\n",
    "    \n",
    "    words = ''\n",
    "    prob = model2.forward(data, new_seq=True)\n",
    "    idx, word = get_word(prob, idx2word, sample)\n",
    "    while idx != eos_idx:\n",
    "        words += word + ' '\n",
    "        prob = model2.forward(np.array([idx]))\n",
    "        idx, word = get_word(prob, idx2word, sample)\n",
    "    \n",
    "    return words.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2 : $\n",
      "33 : 10\n",
      "11 : ,\n",
      "24 : 000\n",
      "6310 : gold\n",
      "400 : ?\n",
      "42567 : <EOS>\n"
     ]
    }
   ],
   "source": [
    "X = text_2_indices(word2idx, '$10,000 Gold?')\n",
    "for x in X:\n",
    "    print(x, ':', idx2word[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'тяжелое положение китая также приведет к идеям участия соседней <UNK> , наряду с ее акцентом на борьбу <UNK> к согласованной эпидемий <UNK> промышленности для того , чтобы принимать решительность в том , сколько государства полностью <UNK> с <UNK> <UNK> <UNK> . но без разрешения такого разрешения поведения ценностей , <UNK> к их собственным обязательствам , вызывают гораздо обвинения для <UNK> соседа , нежели построение политических исследований , таких как культура <UNK> спорта на жизнью 1907 <UNK> и акции могут <UNK> свое внимание от определенных <UNK> химического животных ежегодно .'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "translate('$10,000 Gold?', model, idx2word, sample=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
